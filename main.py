import requests
import feedparser
from datetime import datetime, timedelta
import os
from newspaper import Article, Config

# ==========================================
# 1. ì„¤ì • ë° ì¤€ë¹„
# ==========================================
NOTION_TOKEN = os.environ['NOTION_TOKEN']
DATABASE_ID = os.environ['DATABASE_ID']

headers = {
    "Authorization": "Bearer " + NOTION_TOKEN,
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# ==========================================
# 2. ì²­ì†Œë¶€ (3ì¼ ì§€ë‚œ ë‰´ìŠ¤ ìë™ ì‚­ì œ)
# ==========================================
def delete_old_news():
    print("ğŸ§¹ [ì²­ì†Œ] 3ì¼ ì§€ë‚œ ë‰´ìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...")
    
    three_days_ago = (datetime.now() - timedelta(days=3)).strftime("%Y-%m-%d")
    
    query_url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    payload = {
        "filter": {
            "property": "ë‚ ì§œ",
            "date": {"on_or_before": three_days_ago}
        }
    }
    
    response = requests.post(query_url, headers=headers, json=payload)
    results = response.json().get("results", [])

    if not results:
        print("   - ì‚­ì œí•  ì˜¤ë˜ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for page in results:
        page_id = page["id"]
        requests.patch(f"https://api.notion.com/v1/pages/{page_id}", headers=headers, json={"archived": True})
        print(f"   - ğŸ—‘ï¸ ì‚­ì œë¨ (ID: {page_id})")

# ==========================================
# 3. ë³¸ë¬¸ ì¶”ì¶œ
# ==========================================
def get_full_article(url, summary_fallback=""):
    try:
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        config.request_timeout = 10
        
        article = Article(url, language='ko', config=config)
        article.download()
        article.parse()
        
        if len(article.text) < 50:
            if summary_fallback:
                return f"âš ï¸ [ë³´ì•ˆ ì°¨ë‹¨] ê¸°ì‚¬ ë³¸ë¬¸ ìŠ¤í¬ë©ì´ ë§‰í˜€ ìš”ì•½ë³¸ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n\n{summary_fallback}"
            else:
                return "ë³¸ë¬¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë¬¸ ë§í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        return article.text
    except:
        if summary_fallback:
            return f"âš ï¸ [ì ‘ì† ì—ëŸ¬] ë³¸ë¬¸ ëŒ€ì‹  ìš”ì•½ë³¸ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n\n{summary_fallback}"
        return "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"

# ==========================================
# 4. ë…¸ì…˜ ì—…ë¡œë“œ (ì•„ì´ì½˜ ì„¤ì • ê¸°ëŠ¥ ì¶”ê°€ë¨!)
# ==========================================
def create_page(category, source_name, title, link, date, content, icon_emoji):
    url = "https://api.notion.com/v1/pages"
    
    final_title = f"[{source_name}] {title}"

    if len(content) > 1800:
        content = content[:1800] + "\n...(ì¤‘ëµ)... (ì „ì²´ ë‚´ìš©ì€ ì•„ë˜ ë§í¬ í™•ì¸)"

    data = {
        "parent": {"database_id": DATABASE_ID},
        # -----------------------------------------------------
        # [NEW] ì—¬ê¸°ì— ì•„ì´ì½˜ì„ ì„¤ì •í•˜ëŠ” ì½”ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.
        # -----------------------------------------------------
        "icon": {
            "type": "emoji",
            "emoji": icon_emoji
        },
        "properties": {
            "ì´ë¦„": {"title": [{"text": {"content": final_title}}]},
            "URL": {"url": link},
            "ë‚ ì§œ": {"date": {"start": date}},
            "ì¹´í…Œê³ ë¦¬": {"select": {"name": category}}
        },
        "children": [
            {
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"text": {"content": "ê¸°ì‚¬ ë‚´ìš©"}}],
                    "icon": {"emoji": "ğŸ“°"},
                    "color": "gray_background"
                }
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": content}}]
                }
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": "ğŸ‘‰ ì›ë¬¸ ì „ì²´ ë³´ëŸ¬ê°€ê¸°: " + link, "link": {"url": link}}}]
                }
            }
        ]
    }
    requests.post(url, headers=headers, json=data)

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰
# ==========================================
delete_old_news()

print("\nğŸ“° [ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘] ì•„ì´ì½˜ê¹Œì§€ ì˜ˆì˜ê²Œ ë¶™ì—¬ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤...")

targets = [
    # --- ë¯¸êµ­ ì£¼ì‹ (ì„±ì¡°ê¸°) ---
    {
        "category": "ë¯¸êµ­ì£¼ì‹",
        "source": "í•œê²½ê¸€ë¡œë²Œ",
        "rss": "https://rss.hankyung.com/feed/international",
        "icon": "ğŸ‡ºğŸ‡¸" 
    },
    {
        "category": "ë¯¸êµ­ì£¼ì‹",
        "source": "ì¸ë² ìŠ¤íŒ…",
        "rss": "https://kr.investing.com/rss/news_285.rss",
        "icon": "ğŸ‡ºğŸ‡¸"
    },
    
    # --- êµ­ë‚´ ì£¼ì‹ (íƒœê·¹ê¸°) ---
    {
        "category": "êµ­ë‚´ì£¼ì‹",
        "source": "í•œêµ­ê²½ì œ",
        "rss": "https://rss.hankyung.com/feed/stock",
        "icon": "ğŸ‡°ğŸ‡·"
    },
    {
        "category": "êµ­ë‚´ì£¼ì‹",
        "source": "ë§¤ì¼ê²½ì œ",
        "rss": "https://www.mk.co.kr/rss/50200011/",
        "icon": "ğŸ‡°ğŸ‡·"
    },

    # --- ì½”ì¸ (ë™ì „) ---
    {
        "category": "ì½”ì¸",
        "source": "ì½”ì¸ë°ìŠ¤í¬",
        "rss": "https://www.tokenpost.kr/rss",
        "icon": "ğŸª™"
    }
]

for target in targets:
    category = target["category"]
    source = target["source"]
    rss_url = target["rss"]
    icon = target["icon"] # ì•„ì´ì½˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    
    print(f"\nğŸ” [{category} - {source}] ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    try:
        feed = feedparser.parse(rss_url)
        count = 0
        MAX_ARTICLES = 4 
        
        for entry in feed.entries:
            if count >= MAX_ARTICLES:
                break
                
            if hasattr(entry, 'published_parsed'):
                dt = datetime(*entry.published_parsed[:6]).isoformat()
            else:
                dt = datetime.now().isoformat()
            
            summary_fallback = entry.get('description', '').replace('<p>', '').replace('</p>', '').replace('<br>', '\n')

            full_text = get_full_article(entry.link, summary_fallback)
            
            # create_page í•¨ìˆ˜ì— icon ì •ë³´ë„ ê°™ì´ ë„˜ê²¨ì¤ë‹ˆë‹¤!
            create_page(category, source, entry.title, entry.link, dt, full_text, icon)
            
            print(f"   âœ… ì €ì¥ ì™„ë£Œ: {icon} [{source}] {entry.title}")
            
            count += 1

    except Exception as e:
        print(f"   âŒ {source} ì—ëŸ¬: {e}")

print("\nğŸ‰ ëª¨ë“  ë‰´ìŠ¤ ë°°ë‹¬ ì™„ë£Œ! ë…¸ì…˜ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
