import requests
import feedparser
from datetime import datetime, timedelta
import os
from newspaper import Article, Config

# ==========================================
# 1. ê¸°ë³¸ ì„¤ì •
# ==========================================
NOTION_TOKEN = os.environ['NOTION_TOKEN']
DATABASE_ID = os.environ['DATABASE_ID']

headers = {
    "Authorization": "Bearer " + NOTION_TOKEN,
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# ==========================================
# 2. 3ì¼ ì§€ë‚œ ë‰´ìŠ¤ ìë™ ì‚­ì œ
# ==========================================
def delete_old_news():
    print("ğŸ§¹ [ì²­ì†Œ] 3ì¼ ì§€ë‚œ ë‰´ìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...")
    three_days_ago = (datetime.now() - timedelta(days=3)).strftime("%Y-%m-%d")
    
    query_url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    payload = {
        "filter": {
            "property": "ë‚ ì§œ",
            "date": {"on_or_before": three_days_ago}
        }
    }
    
    response = requests.post(query_url, headers=headers, json=payload)
    results = response.json().get("results", [])

    if not results:
        print("   - ì‚­ì œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for page in results:
        page_id = page["id"]
        requests.patch(f"https://api.notion.com/v1/pages/{page_id}", headers=headers, json={"archived": True})
        print(f"   - ğŸ—‘ï¸ ì‚­ì œë¨ (ID: {page_id})")

# ==========================================
# 3. ë³¸ë¬¸ ì¶”ì¶œ (ë³´ì•ˆ ê°•í™” ì‚¬ì´íŠ¸ ëŒ€ì‘)
# ==========================================
def get_full_article(url, summary_fallback=""):
    try:
        # ì¸ë² ìŠ¤íŒ…ë‹·ì»´ ê°™ì€ ê³³ì€ ë´‡ì„ ë§‰ìœ¼ë¯€ë¡œ ì‚¬ëŒì¸ ì²™ ìœ„ì¥
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36'
        config.request_timeout = 15
        
        article = Article(url, language='ko', config=config)
        article.download()
        article.parse()
        
        # ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(ì°¨ë‹¨ë¨) RSS ìš”ì•½ë³¸ì´ë¼ë„ ë¦¬í„´
        if len(article.text) < 50:
            if summary_fallback:
                return f"âš ï¸ [ë³´ì•ˆ ì°¨ë‹¨] ë³¸ë¬¸ ì¶”ì¶œì´ ë§‰í˜€ ìš”ì•½ë³¸ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n\n{summary_fallback}"
            else:
                return "ë³¸ë¬¸ ë³´ì•ˆ ì„¤ì •ìœ¼ë¡œ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë¬¸ ë§í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        return article.text
    except:
        # ì—ëŸ¬ ë‚˜ë©´ ìš”ì•½ë³¸ ë¦¬í„´
        if summary_fallback:
            return f"âš ï¸ [ì ‘ì† ì—ëŸ¬] ë³¸ë¬¸ ëŒ€ì‹  ìš”ì•½ë³¸ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n\n{summary_fallback}"
        return "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ==========================================
# 4. ë…¸ì…˜ ì—…ë¡œë“œ
# ==========================================
def create_page(category, source_name, title, link, date, content):
    url = "https://api.notion.com/v1/pages"
    
    # ì œëª©ì— ì¶œì²˜ í‘œì‹œ
    final_title = f"[{source_name}] {title}"

    # ë³¸ë¬¸ ê¸¸ì´ ìë¥´ê¸°
    if len(content) > 1800:
        content = content[:1800] + "\n...(ì¤‘ëµ)... (ì „ì²´ ë‚´ìš©ì€ ì•„ë˜ ë§í¬ í™•ì¸)"

    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "ì´ë¦„": {"title": [{"text": {"content": final_title}}]},
            "URL": {"url": link},
            "ë‚ ì§œ": {"date": {"start": date}},
            "ì¹´í…Œê³ ë¦¬": {"select": {"name": category}}
        },
        "children": [
            {
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"text": {"content": "ê¸°ì‚¬ ë‚´ìš©"}}],
                    "icon": {"emoji": "ğŸ“°"},
                    "color": "gray_background"
                }
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": content}}]
                }
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": "ğŸ‘‰ ì›ë¬¸ ì „ì²´ ë³´ëŸ¬ê°€ê¸°: " + link, "link": {"url": link}}}]
                }
            }
        ]
    }
    
    requests.post(url, headers=headers, json=data)

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ (ì¸ë² ìŠ¤íŒ…ë‹·ì»´ ì¶”ê°€ë¨)
# ==========================================
delete_old_news()

print("\nğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")

targets = [
    {
        "category": "ë¯¸êµ­ì£¼ì‹",
        "source": "ì¸ë² ìŠ¤íŒ…", # ì¸ë² ìŠ¤íŒ…ë‹·ì»´ í•œêµ­íŒ (ì¦ì‹œ ë‰´ìŠ¤)
        "rss": "https://kr.investing.com/rss/news_285.rss" 
    },
    {
        "category": "êµ­ë‚´ì£¼ì‹",
        "source": "ë§¤ì¼ê²½ì œ", # ë§¤ì¼ê²½ì œ ì¦ê¶Œ
        "rss": "https://www.mk.co.kr/rss/50200011/"
    },
    {
        "category": "ì½”ì¸",
        "source": "í† í°í¬ìŠ¤íŠ¸", # ì½”ì¸ ì „ë¬¸
        "rss": "https://www.tokenpost.kr/rss"
    }
]

for target in targets:
    category = target["category"]
    source = target["source"]
    rss_url = target["rss"]
    
    print(f"\nğŸ” [{category}] ê°€ì ¸ì˜¤ëŠ” ì¤‘ ({source})...")
    
    try:
        feed = feedparser.parse(rss_url)
        
        count = 0
        MAX_ARTICLES = 4
        
        for entry in feed.entries:
            if count >= MAX_ARTICLES:
                break
                
            # ë‚ ì§œ
            if hasattr(entry, 'published_parsed'):
                dt = datetime(*entry.published_parsed[:6]).isoformat()
            else:
                dt = datetime.now().isoformat()
            
            # RSSì— í¬í•¨ëœ ì§§ì€ ìš”ì•½ (í˜¹ì‹œ ë³¸ë¬¸ ëª» ê°€ì ¸ì˜¬ ë•Œ ëŒ€ë¹„ìš©)
            summary_fallback = entry.get('description', '')
            # HTML íƒœê·¸ ì œê±° (ê°„ë‹¨íˆ)
            summary_fallback = summary_fallback.replace('<p>', '').replace('</p>', '').replace('<br>', '\n')

            # ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„
            full_text = get_full_article(entry.link, summary_fallback)
            
            # ë…¸ì…˜ ì €ì¥
            create_page(category, source, entry.title, entry.link, dt, full_text)
            print(f"   âœ… ì €ì¥: [{source}] {entry.title}")
            
            count += 1

    except Exception as e:
        print(f"   âŒ ì—ëŸ¬: {e}")

print("\nğŸ‰ ì™„ë£Œ!")
