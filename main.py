import requests
import feedparser
from datetime import datetime, timedelta
import os
from newspaper import Article, Config

# ==========================================
# 1. ê¸°ë³¸ ì„¤ì •
# ==========================================
NOTION_TOKEN = os.environ['NOTION_TOKEN']
DATABASE_ID = os.environ['DATABASE_ID']

headers = {
    "Authorization": "Bearer " + NOTION_TOKEN,
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# ==========================================
# 2. [ì²­ì†Œë¶€] 3ì¼ ì§€ë‚œ ë‰´ìŠ¤ ìë™ ì‚­ì œ
# ==========================================
def delete_old_news():
    print("ğŸ§¹ [ì²­ì†Œ ì‹œì‘] 3ì¼ ì§€ë‚œ ë‰´ìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...")
    
    # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ 3ì¼ ì „ ê³„ì‚°
    three_days_ago = (datetime.now() - timedelta(days=3)).strftime("%Y-%m-%d")
    
    # ë…¸ì…˜ì— ì¿¼ë¦¬: ë‚ ì§œê°€ 3ì¼ ì „(í¬í•¨)ë³´ë‹¤ ê³¼ê±°ì¸ ê²ƒë“¤
    query_url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    payload = {
        "filter": {
            "property": "ë‚ ì§œ",
            "date": {
                "on_or_before": three_days_ago
            }
        }
    }
    
    response = requests.post(query_url, headers=headers, json=payload)
    results = response.json().get("results", [])

    if not results:
        print("   - ì‚­ì œí•  ì˜¤ë˜ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¹¨ë—í•¨)")
        return

    for page in results:
        page_id = page["id"]
        # íœ´ì§€í†µìœ¼ë¡œ ë³´ë‚´ê¸° (Archive)
        delete_url = f"https://api.notion.com/v1/pages/{page_id}"
        requests.patch(delete_url, headers=headers, json={"archived": True})
        print(f"   - ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ (ID: {page_id})")

# ==========================================
# 3. [ë³¸ë¬¸ ì¶”ì¶œ] ì‹ ë¬¸ ê¸°ì‚¬ ë‚´ìš© ê¸ì–´ì˜¤ê¸°
# ==========================================
def get_full_article(url):
    try:
        # ë´‡ ì°¨ë‹¨ ë°©ì§€ìš© ì„¤ì •
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36'
        config.request_timeout = 10

        article = Article(url, language='ko', config=config)
        article.download()
        article.parse()
        
        # ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(ë¡œê·¸ì¸ í•„ìš” ë“±) ì—ëŸ¬ ë©”ì‹œì§€
        if len(article.text) < 50:
            return "ë³¸ë¬¸ ë³´ì•ˆ ì„¤ì •ìœ¼ë¡œ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë¬¸ ë§í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        return article.text
    except Exception as e:
        return "ë³¸ë¬¸ ì¶”ì¶œ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ==========================================
# 4. [ì—…ë¡œë“œ] ë…¸ì…˜ì— ì˜ˆì˜ê²Œ ê¸€ì“°ê¸°
# ==========================================
def create_page(category, title, link, date, content):
    url = "https://api.notion.com/v1/pages"
    
    # ë…¸ì…˜ ê¸€ììˆ˜ ì œí•œ(2000ì) ê³ ë ¤í•´ì„œ ìë¥´ê¸°
    if len(content) > 1800:
        content = content[:1800] + "\n\n...(ì¤‘ëµ)... (ì „ì²´ ë‚´ìš©ì€ ì•„ë˜ ë§í¬ í™•ì¸)"

    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "ì´ë¦„": {"title": [{"text": {"content": title}}]},
            "URL": {"url": link},
            "ë‚ ì§œ": {"date": {"start": date}},
            "ì¹´í…Œê³ ë¦¬": {"select": {"name": category}}
        },
        "children": [
            {
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"text": {"content": "ìë™ ì¶”ì¶œëœ ê¸°ì‚¬ ë³¸ë¬¸ì…ë‹ˆë‹¤."}}],
                    "icon": {"emoji": "ğŸ“°"},
                    "color": "gray_background"
                }
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": content}}]
                }
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": "ğŸ‘‰ ì›ë¬¸ ì „ì²´ ë³´ëŸ¬ê°€ê¸°: " + link, "link": {"url": link}}}]
                }
            }
        ]
    }
    
    requests.post(url, headers=headers, json=data)

# ==========================================
# 5. [ë©”ì¸] ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘
# ==========================================
# ë¨¼ì € ì²­ì†Œë¶€í„° í•˜ê³  ì‹œì‘
delete_old_news()

print("\nğŸ“° [ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘] ì£¼ìš” ì–¸ë¡ ì‚¬ì˜ í•µì‹¬ ê¸°ì‚¬ 4ê°œì”© ê°€ì ¸ì˜µë‹ˆë‹¤...")

# í€„ë¦¬í‹° ê²€ì¦ëœ RSS ì£¼ì†Œ ëª©ë¡
targets = [
    {
        "category": "ë¯¸êµ­ì£¼ì‹",
        "rss": "https://rss.hankyung.com/feed/international" # í•œêµ­ê²½ì œ êµ­ì œë©´
    },
    {
        "category": "êµ­ë‚´ì£¼ì‹",
        "rss": "https://www.mk.co.kr/rss/50200011/" # ë§¤ì¼ê²½ì œ ì¦ê¶Œë©´
    },
    {
        "category": "ì½”ì¸",
        "rss": "https://www.tokenpost.kr/rss" # í† í°í¬ìŠ¤íŠ¸
    }
]

for target in targets:
    category = target["category"]
    rss_url = target["rss"]
    
    print(f"\nğŸ” [{category}] ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    try:
        feed = feedparser.parse(rss_url)
        
        # ì¹´í…Œê³ ë¦¬ ë‹¹ ìµœì‹  ê¸°ì‚¬ 4ê°œë§Œ ê°€ì ¸ì˜´
        count = 0
        MAX_ARTICLES = 4 
        
        for entry in feed.entries:
            if count >= MAX_ARTICLES:
                break
                
            # ë‚ ì§œ ì²˜ë¦¬
            if hasattr(entry, 'published_parsed'):
                dt = datetime(*entry.published_parsed[:6]).isoformat()
            else:
                dt = datetime.now().isoformat()
            
            # ë³¸ë¬¸ ì¶”ì¶œ
            full_text = get_full_article(entry.link)
            
            # ë…¸ì…˜ ì €ì¥
            create_page(category, entry.title, entry.link, dt, full_text)
            print(f"   âœ… ì €ì¥: {entry.title}")
            
            count += 1

    except Exception as e:
        print(f"   âŒ ì—ëŸ¬ ë°œìƒ: {e}")

print("\nğŸ‰ ëª¨ë“  ë‰´ìŠ¤ ë°°ë‹¬ ì™„ë£Œ!")
